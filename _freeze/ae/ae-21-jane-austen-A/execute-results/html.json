{
  "hash": "b037c7722634e83c88bb63401a8330c2",
  "result": {
    "markdown": "---\ntitle: \"He replied / she cried: Text mining and gender roles\"\ncategories: \n  - Application exercise\n  - Answers\neditor: visual\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: callout-important\nThese are suggested answers.\nThis document should be used as reference only, it's not designed to be an exhaustive key.\n:::\n\n# Introduction\n\n> Which verbs follow \"she\" and \"he\" pronouns in Jane Austen novels?\n> Are they similar or different?\n\n**Goal:** Use text mining methods to explore whether verbs that follow she and he pronouns are similar or different.\n\n**Inspirations:**\n\n-   Blog post by Julia Silge: [https://juliasilge.com/blog/gender-pronouns](https://juliasilge.com/blog/gender-pronouns/)\n-   Jockers, Matthew, and Gabi Kirilloff. [\"Understanding gender and character agency in the 19th century novel.\"](https://culturalanalytics.org/article/11066.pdf) Journal of Cultural Analytics 2.2 (2016): 11066.\n\n## Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(knitr)\nlibrary(janeaustenr) # install.packages(\"janeaustenr)\n```\n:::\n\n\n## Data\n\nThe **janeaustenr** package offers a function, `austen_books()`, that returns a tidy data frame of Jane Austen's 6 completed, published novels.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nausten_books <- austen_books() |>\n  filter(text != \"\")\n```\n:::\n\n\n-   **Demo:** Which books are included in the dataset?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nausten_books |>\n  distinct(book)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 1\n  book               \n  <fct>              \n1 Sense & Sensibility\n2 Pride & Prejudice  \n3 Mansfield Park     \n4 Emma               \n5 Northanger Abbey   \n6 Persuasion         \n```\n:::\n:::\n\n\n# Word frequencies\n\n-   **Question:** What would you expect to be the most common word in Jane Austen novels? Would you expect it to be the same across all books?\n\nAnswers may vary.\n\n-   **Demo:** Split the `text` column into word tokens.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nausten_words <- austen_books |>\n  unnest_tokens(output = word, input = text) # token = \"words\" by default\n```\n:::\n\n\n-   **Your turn:** Discover the top 10 most commonly used words in each of Jane Austen's books.\n\nWith stop words:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nausten_words |>\n  count(book, word, sort = TRUE) |>\n  group_by(book) |>\n  slice_head(n = 10) |>\n  pivot_wider(\n    names_from = book, \n    values_from = n,\n    values_fn = as.character,\n    values_fill = \"Not in top 10\"\n    ) |>\n  kable()\n```\n\n::: {.cell-output-display}\n|word |Sense & Sensibility |Pride & Prejudice |Mansfield Park |Emma          |Northanger Abbey |Persuasion    |\n|:----|:-------------------|:-----------------|:--------------|:-------------|:----------------|:-------------|\n|to   |4116                |4162              |5475           |5239          |2244             |2808          |\n|the  |4105                |4331              |6206           |5201          |3179             |3329          |\n|of   |3571                |3610              |4778           |4291          |2358             |2570          |\n|and  |3490                |3585              |5438           |4896          |2306             |2800          |\n|her  |2543                |2203              |3082           |2462          |1562             |1203          |\n|a    |2092                |1954              |3099           |3129          |1540             |1594          |\n|i    |1998                |2065              |2358           |3177          |1285             |Not in top 10 |\n|in   |1979                |1880              |2512           |Not in top 10 |1268             |1389          |\n|was  |1861                |1843              |2651           |2398          |1114             |1337          |\n|it   |1755                |Not in top 10     |2272           |2528          |1106             |Not in top 10 |\n|she  |Not in top 10       |1695              |Not in top 10  |2340          |Not in top 10    |1146          |\n|had  |Not in top 10       |Not in top 10     |Not in top 10  |Not in top 10 |Not in top 10    |1187          |\n:::\n:::\n\n\n-   **Demo:** Let's do better, without the \"stop words\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstop_words\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,149 × 2\n   word        lexicon\n   <chr>       <chr>  \n 1 a           SMART  \n 2 a's         SMART  \n 3 able        SMART  \n 4 about       SMART  \n 5 above       SMART  \n 6 according   SMART  \n 7 accordingly SMART  \n 8 across      SMART  \n 9 actually    SMART  \n10 after       SMART  \n# … with 1,139 more rows\n```\n:::\n:::\n\n\nWithout stop words:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nausten_words |>\n  anti_join(stop_words) |>\n  count(book, word, sort = TRUE) |>\n  group_by(book) |>\n  slice_head(n = 10) |>\n  ggplot(aes(y = word, x = n, fill = book)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~book, scales = \"free\") +\n  labs(y = NULL)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\n```\n:::\n\n::: {.cell-output-display}\n![](ae-21-jane-austen-A_files/figure-html/top-without-stop-words-1.png){width=672}\n:::\n:::\n\n\nWith better ordering:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nausten_words |>\n  anti_join(stop_words) |>\n  count(book, word, sort = TRUE) |>\n  group_by(book) |>\n  slice_head(n = 10) |>\n  ggplot(aes(y = reorder_within(word, n, book), x = n, fill = book)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~book, scales = \"free\") +\n  scale_y_reordered() +\n  labs(y = NULL)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\n```\n:::\n\n::: {.cell-output-display}\n![](ae-21-jane-austen-A_files/figure-html/top-without-stop-words-better-1.png){width=672}\n:::\n:::\n\n\n# Bigram frequencies\n\nAn n-gram is a contiguous series of $n$ words from a text; e.g., a **bigram** is a pair of words, with $n = 2$.\n\n-   **Demo:** Split the `text` column into bigram tokens.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nausten_bigrams <- austen_books |>\n  unnest_tokens(bigram, text, token = \"ngrams\", n = 2) |>\n  filter(!is.na(bigram))\n\nausten_bigrams\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 662,783 × 2\n   book                bigram         \n   <fct>               <chr>          \n 1 Sense & Sensibility sense and      \n 2 Sense & Sensibility and sensibility\n 3 Sense & Sensibility by jane        \n 4 Sense & Sensibility jane austen    \n 5 Sense & Sensibility chapter 1      \n 6 Sense & Sensibility the family     \n 7 Sense & Sensibility family of      \n 8 Sense & Sensibility of dashwood    \n 9 Sense & Sensibility dashwood had   \n10 Sense & Sensibility had long       \n# … with 662,773 more rows\n```\n:::\n:::\n\n\n-   **Your turn:** Visualize the frequencies of top 10 bigrams in each of Jane Austen's books.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nausten_bigrams |>\n  count(book, bigram, sort = TRUE) |>\n  group_by(book) |>\n  slice_head(n = 10) |>\n  ggplot(aes(y = reorder_within(bigram, n, book), x = n, fill = book)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~book, scales = \"free\") +\n  scale_y_reordered() +\n  labs(y = NULL)\n```\n\n::: {.cell-output-display}\n![](ae-21-jane-austen-A_files/figure-html/top-bigrams-1.png){width=672}\n:::\n:::\n\n\n# Verbs that follow she or he\n\nFirst, let's define the pronouns of interest:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npronouns <- c(\"he\", \"she\")\n```\n:::\n\n\n-   **Demo:** Filter the dataset for bigrams that start with either \"she\" or \"he\" and calculate the number of times these bigrams appeared.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbigram_counts <- austen_bigrams |>\n  count(bigram, sort = TRUE) |>\n  separate(bigram, into = c(\"word1\", \"word2\"), sep = \" \") |>\n  filter(word1 %in% pronouns) |>\n  count(word1, word2, wt = n, sort = TRUE) |>\n  rename(total = n)\n\nbigram_counts\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,490 × 3\n   word1 word2 total\n   <chr> <chr> <int>\n 1 she   had    1405\n 2 she   was    1309\n 3 he    had     965\n 4 he    was     844\n 5 she   could   767\n 6 he    is      385\n 7 she   would   348\n 8 she   is      311\n 9 he    could   281\n10 he    would   244\n# … with 1,480 more rows\n```\n:::\n:::\n\n\n-   **Discussion:** What can we do next to see if there is a difference in the types of verbs that follow \"he\" vs. \"she\"?\n\nAnswers may vary.\n\n-   **Demo:** Which words have about the same likelihood of following \"he\" or \"she\" in Jane Austen's novels?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_ratios <- bigram_counts |>\n  group_by(word2) |>\n  filter(sum(total) > 10) |>\n  ungroup() |>\n  pivot_wider(names_from = word1, values_from = total, values_fill = 0) |>\n  arrange(word2) |>\n  mutate(\n    she = (she+1)/sum(she+1),\n    he = (he+1)/sum(he+1),\n    logratio = log(she / he, base = 2)\n  ) |>\n  arrange(desc(logratio))\n\nword_ratios\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 158 × 4\n   word2          she       he logratio\n   <chr>        <dbl>    <dbl>    <dbl>\n 1 remembered 0.00167 0.000165     3.34\n 2 read       0.00274 0.000495     2.47\n 3 resolved   0.00131 0.000330     1.99\n 4 felt       0.0216  0.00577      1.90\n 5 longed     0.00167 0.000495     1.75\n 6 received   0.00214 0.000659     1.70\n 7 feared     0.00238 0.000824     1.53\n 8 dared      0.00274 0.000989     1.47\n 9 heard      0.00500 0.00181      1.46\n10 tried      0.00226 0.000824     1.46\n# … with 148 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nword_ratios |> \n  arrange(abs(logratio))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 158 × 4\n   word2         she       he logratio\n   <chr>       <dbl>    <dbl>    <dbl>\n 1 ought    0.00548  0.00561   -0.0330\n 2 walked   0.00369  0.00379   -0.0385\n 3 would    0.0416   0.0404     0.0413\n 4 loves    0.000953 0.000989  -0.0541\n 5 too      0.000953 0.000989  -0.0541\n 6 paused   0.00155  0.00148    0.0614\n 7 turned   0.00310  0.00297    0.0614\n 8 very     0.00155  0.00148    0.0614\n 9 had      0.167    0.159      0.0724\n10 listened 0.00226  0.00214    0.0784\n# … with 148 more rows\n```\n:::\n:::\n\n\n-   **Demo:** Which words have different likelihoods of following \"he\" or \"she\" in Jane Austen's novels?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_ratios |>\n  mutate(abslogratio = abs(logratio)) |>\n  group_by(logratio < 0) |>\n  top_n(15, abslogratio) |>\n  ungroup() |>\n  mutate(word = reorder(word2, logratio)) |>\n  ggplot(aes(word, logratio, color = logratio < 0)) +\n  geom_segment(\n    aes(\n      x = word, xend = word,\n      y = 0, yend = logratio\n    ),\n    linewidth = 1.1, alpha = 0.6\n  ) +\n  geom_point(size = 3.5) +\n  coord_flip() +\n  labs(\n    x = NULL,\n    y = \"Relative appearance after 'she' compared to 'he'\",\n    title = \"Words paired with 'he' and 'she' in Jane Austen's novels\",\n    subtitle = \"Women remember, read, and feel while men stop, take, and reply\"\n  ) +\n  scale_color_discrete(name = \"\", labels = c(\"More 'she'\", \"More 'he'\")) +\n  scale_y_continuous(\n    breaks = seq(-3, 3),\n    labels = c(\n      \"0.125x\", \"0.25x\", \"0.5x\",\n      \"Same\", \"2x\", \"4x\", \"8x\"\n    )\n  )\n```\n\n::: {.cell-output-display}\n![](ae-21-jane-austen-A_files/figure-html/different-he-she-1.png){width=672}\n:::\n:::\n\n\n# Sentiment analysis\n\nOne way to analyze the sentiment of a text is to consider the text as a combination of its individual words and the sentiment content of the whole text as the sum of the sentiment content of the individual words.\nThis isn't the only way to approach sentiment analysis, but it is an often-used approach, and an approach that naturally takes advantage of the tidy tool ecosystem.[^1]\n\n[^1]: Tidy Text Mining: <https://www.tidytextmining.com/sentiment.html>.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsentiments <- get_sentiments(\"afinn\")\nsentiments\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,477 × 2\n   word       value\n   <chr>      <dbl>\n 1 abandon       -2\n 2 abandoned     -2\n 3 abandons      -2\n 4 abducted      -2\n 5 abduction     -2\n 6 abductions    -2\n 7 abhor         -3\n 8 abhorred      -3\n 9 abhorrent     -3\n10 abhors        -3\n# … with 2,467 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbigram_counts |>\n  left_join(sentiments, by = c(\"word2\" = \"word\")) |>\n  filter(!is.na(value)) |>\n  mutate(sentiment = total * value) |>\n  group_by(word1) |>\n  arrange(desc(abs(sentiment))) |>\n  slice_head(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 20 × 5\n# Groups:   word1 [2]\n   word1 word2      total value sentiment\n   <chr> <chr>      <int> <dbl>     <dbl>\n 1 he    loved         16     3        48\n 2 he    cried         11    -2       -22\n 3 he    liked         10     2        20\n 4 he    trusted        8     2        16\n 5 he    bore           7    -2       -14\n 6 he    smiling        7     2        14\n 7 he    stopped       13    -1       -13\n 8 he    delighted      4     3        12\n 9 he    likes          5     2        10\n10 he    smiled         5     2        10\n11 she   cried         44    -2       -88\n12 she   loved         17     3        51\n13 she   liked         17     2        34\n14 she   trusted       13     2        26\n15 she   resolved      10     2        20\n16 she   rejoiced       5     4        20\n17 she   likes          8     2        16\n18 she   lost           5    -3       -15\n19 she   determined     6     2        12\n20 she   dreaded        6    -2       -12\n```\n:::\n:::\n",
    "supporting": [
      "ae-21-jane-austen-A_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}